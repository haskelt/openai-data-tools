{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983b1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3196256",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930a907",
   "metadata": {},
   "source": [
    "### Import the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a266423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gptdatacoder import GPTDataCoder\n",
    "import openai_data_coder as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54db5873-fe6a-46d8-bc87-d1cd4a5648f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'openai_data_coder' from '/home/haskelt/openai-data-tools/openai_data_coder.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02b132",
   "metadata": {},
   "source": [
    "### Load some data to code\n",
    "\n",
    "This example loads data from a CSV into a Pandas dataframe. But you can load your data any way you like, all you need is a list where each item is a string with the text to be coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0a060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('./social_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c960f",
   "metadata": {},
   "source": [
    "### Create a coder object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c86b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder = dc.OpenAIDataCoder(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "    model = 'gpt-3.5-turbo', \n",
    "    instructions = 'You will be provided with sentences from social media posts. For each sentence, determine if the sentence mentions food, cooking, or eating.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368830b",
   "metadata": {},
   "source": [
    "To make requests to the OpenAI API, you will need an API key so the system knows who you are (and can charge you for the requests you make). You can create an API key on the OpenAI site on this page:\n",
    "\n",
    "https://platform.openai.com/account/api-keys\n",
    "\n",
    "Anyone with the API key can make requests using your account, so I don’t recommend storing it directly in your script. In the example above, it has been stored in an environment variable.\n",
    "\n",
    "You will need to specify what model you want to make requests to. In this example, we are using gpt-3.5-turbo.\n",
    "\n",
    "Finally, this is where you provide instructions for how ChatGPT should code the items it sees. In addition to the instructions you provide, ChatGPT will be asked to provide a yes/no response for each item, so make sure to write your instructions with that in mind. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183a752",
   "metadata": {},
   "source": [
    "### Code some items\n",
    "\n",
    "This will ask ChatGPT to code each item in the list you provide. It returns a list of 0’s and 1’s, where 0 means the code was not applied, and 1 means it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83cb1bde",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'api_requestor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_coding \u001b[38;5;241m=\u001b[39m \u001b[43mmy_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/openai-data-tools/openai_data_coder.py:113\u001b[0m, in \u001b[0;36mOpenAIDataCoder.code\u001b[0;34m(self, items, num_runs, coding_type, timeout, mode)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcode\u001b[39m(\u001b[38;5;28mself\u001b[39m, items, num_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, coding_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlive\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    112\u001b[0m     openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m--> 113\u001b[0m     \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_requestor\u001b[49m\u001b[38;5;241m.\u001b[39mTIMEOUT_SECS \u001b[38;5;241m=\u001b[39m timeout\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoding_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'api_requestor'"
     ]
    }
   ],
   "source": [
    "my_coding = my_coder.code(my_data['item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea364c",
   "metadata": {},
   "source": [
    "### Evaluate the coding\n",
    "\n",
    "If you know the correct coding for each item, you can calculate classification metrics. In the example below, `training_data[‘target’]` is a list with the correct response for each item, again as a list of 0’s and 1’s. This will return accuracy, precision, and recall based on the last coding run with this coder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570af5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder.classification_metrics(my_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f218f",
   "metadata": {},
   "source": [
    "### Get an item-by-item scoring\n",
    "\n",
    "If you want to know how ChatGPT did for each item, you can score its responses. This will return a list of 0’s and 1’s, where 1 indicates a correct response from ChatGPT and 0 indicates an incorrect response. Examining the specific items ChatGPT is getting wrong can help you revise your instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a77ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder.score(my_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1420b",
   "metadata": {},
   "source": [
    "## Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebad502",
   "metadata": {},
   "source": [
    "### Few-shot learning\n",
    "\n",
    "You may be able to improve coding performance by providing ChatGPT with some examples where you specify how they should be coded and why. Examples should be in the form of a list of dicts, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [{'item': 'My mom used to bake bread all the time when I was a kid.',\n",
    "  'target': 1,\n",
    "  'explanation': 'The sentence mentions baking, which is a kind of cooking.'},\n",
    " {'item': 'I need to go to the store to buy napkins.',\n",
    "  'target': 0,\n",
    "  'explanation': 'Napkins are used while eating, but the sentence does not directly mention food, cooking, or eating.'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ddb66",
   "metadata": {},
   "source": [
    "You then provide these examples when creating the coder object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder = GPTDataCoder(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"), \n",
    "    model = 'gpt-3.5-turbo', \n",
    "    instructions = 'You will be provided with sentences from social media posts. For each sentence, determine if the sentence mentions food, cooking, or eating.',\n",
    "    examples = examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef76e71",
   "metadata": {},
   "source": [
    "### Multiple coding runs\n",
    "\n",
    "ChatGPT will not necessarily provide the same response each time it is presented with an item. If you are concerned about variability in the responses, you can ask for each item to be coded multiple times. When you ask for multiple runs, the `code` method returns the most common response for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coding = my_coder.code(my_data['item'], num_runs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a36a20",
   "metadata": {},
   "source": [
    "If you want to know how much variability there is across runs, you can ask for the intrarater reliability, which is the proportion of agreement in the AI’s responses across runs. This can range from 0 to 1, with 1 meaning the AI always provided the same response for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder.intrarater_reliability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6103fe",
   "metadata": {},
   "source": [
    "### Examining ChatGPT’s explanations\n",
    "\n",
    "The module asks ChatGPT to explain its answer for every item it codes. This information is stored as part of the coder object, and can be useful to look at when you’re trying to improve performance. You can get the explanation for a particular response like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e07f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder._data['coding_data'][1][3]['explanation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70cffb",
   "metadata": {},
   "source": [
    "This shows the explanation from the 2nd coding run and the 4th item (as usual in Python, arrays use zero-based indexing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c508",
   "metadata": {},
   "source": [
    "### Saving and reloading coding data\n",
    "\n",
    "Once you’ve coded some data, lots of information about the coding is stored as part of the coder object, such as the explanations described in the previous section. However, once your Python session ends, that object goes away, and all that information is lost. If you want to save that information so you can look at it later, you can write it to a file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5de94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder.dump('my_coder_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515c69e",
   "metadata": {},
   "source": [
    "You can then reload it in another session like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997603d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coder.restore('my_coder_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29f87d",
   "metadata": {},
   "source": [
    "Note that you have to create the coder object before you can reload coding data into that object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
